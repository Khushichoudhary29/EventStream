# EventStream Processor

A production-inspired **event-driven backend system** built using **Node.js, Express, and Redis Streams**. This project demonstrates how to design a **reliable, fault-tolerant event ingestion and processing pipeline** with retries, dead-letter handling, metrics, and crash recovery.

This is not a toy queue â€” it mirrors real-world backend patterns used in scalable systems and behaves like a mini Kafka-style pipeline using Redis.

---

## ğŸ” Problem Statement

Modern backend systems often need to:

* Accept events quickly (HTTP APIs)
* Process them asynchronously
* Handle failures safely
* Avoid data loss during crashes

Traditional in-memory queues fail under crashes. This project solves that problem using **Redis Streams**.

---

## âœ… What This Project Does

* Accepts incoming events via REST API
* Stores events durably in Redis Streams
* Processes events using a background consumer
* Retries failed events with limits
* Moves permanently failed events to a Dead Letter Queue (DLQ)
* Recovers unacknowledged events after crashes
* Exposes processing metrics

---

## ğŸ§  Architecture Overview

**Flow:**

Client â†’ Express API â†’ Redis Stream â†’ Stream Processor â†’

* Success â†’ Stored events
* Retry â†’ Re-queued
* Failure â†’ DLQ

**Key Concepts Used:**

* Redis Streams (`XADD`, `XREADGROUP`, `XACK`)
* Consumer Groups
* Pending Entries List (PEL)
* Crash Recovery (`XPENDING`, `XCLAIM`)

---

## ğŸ›  Tech Stack

* **Node.js** (v18+)
* **Express.js** â€“ REST API
* **Redis** â€“ Stream-based message queue
* **ioredis** â€“ Redis client

---

## ğŸ“ Project Structure

```
EventStream/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Express server entry point
â”‚   â”œâ”€â”€ stream.js             # Redis stream & consumer group setup
â”‚   â”œâ”€â”€ streamProcessor.js    # Background event processor
â”‚   â”œâ”€â”€ recovery.js           # Pending event recovery logic
â”‚   â”œâ”€â”€ retry.js              # Retry strategy
â”‚   â”œâ”€â”€ queue.js              # (legacy / optional)
â”‚   â”œâ”€â”€ events.js             # Processed events store
â”‚   â”œâ”€â”€ dlq.js                # Dead Letter Queue
â”‚   â”œâ”€â”€ metrics.js            # Metrics tracking
â”‚   â””â”€â”€ validator.js          # Event validation
â”‚
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## 1ï¸âƒ£ Event Ingestion (index.js)
* Accepts events via REST API
* Validates input

* Assigns:
  * id (UUID)
  * retryCount
  * Pushes events to Redis Stream

ğŸ“Œ Why Redis Streams?
* Persistent
* Ordered
* Supports consumer groups
* Handles crash recovery

## 2ï¸âƒ£ Redis Stream (stream.js)
* Responsibilities:
  * Initialize Redis connection
  * Create stream & consumer group
  * Add events using XADD

ğŸ“Œ Why consumer groups?
  * Multiple workers can scale horizontally
  * Redis tracks which messages are pending
  * Enables recovery if a worker crashes

## 3ï¸âƒ£ Stream Processor (streamProcessor.js)
* Responsibilities:
  * Reads events using XREADGROUP
  * Processes one event at a time
  * Acknowledges events using XACK

Processing logic:

âœ… Success â†’ stored in events.json

ğŸ” Retryable failure â†’ re-added to stream

âŒ Permanent failure â†’ sent to DLQ

ğŸ“Œ This is the heart of the system

## 4ï¸âƒ£ Retry Logic (retry.js)
Controls:
 * Maximum retry attempts
I* ncrementing retry counters

ğŸ“Œ Why retry?

Transient failures (network, timeout) should not kill events.

## 5ï¸âƒ£ Dead Letter Queue (dlq.js)
* Stores permanently failed events
* Keeps:
  * original event
  * failure reason
  * timestamp

ğŸ“Œ Why DLQ?

In production, failed events must be inspected, not deleted.

## 6ï¸âƒ£ Recovery System (recovery.js)
* Uses:
  * XPENDING
  * XCLAIM

* Purpose:
  * Detect messages stuck with crashed consumers
  * Reassign them to active consumers

## 7ï¸âƒ£ Metrics (metrics.js)
* Tracks:
  * processed events
  * failed events
  * retried events

* Exposed via:
  * GET /metrics

ğŸ“Œ Observability is mandatory in real systems

---

## ğŸŒ API Endpoints

### 1ï¸âƒ£ Ingest Event

`POST /events`

**Request Body:**

```json
{
  "type": "USER_SIGNUP",
  "payload": {
    "userId": "123"
  }
}
```

**Response:**

```json
{
  "message": "Event accepted and queued (Redis)",
  "eventId": "uuid"
}
```

---

### 2ï¸âƒ£ View Processed Events

`GET /events`

---

### 3ï¸âƒ£ View Failed Events (DLQ)

`GET /failed-events`

---

### 4ï¸âƒ£ View Metrics

`GET /metrics`

Example metrics:

```json
{
  "processed": 10,
  "failed": 2,
  "retried": 1
}
```

---

## ğŸ” Retry & Failure Handling

* Each event has a retry counter
* Failed events are retried until limit is reached
* After max retries, event is moved to **Dead Letter Queue (DLQ)**

This prevents infinite retry loops.

---

## â™»ï¸ Crash Recovery (Important)

If the server crashes **after reading but before acknowledging** an event:

* Redis keeps the event in the **Pending Entries List (PEL)**
* On restart, `recovery.js`:

  * Scans pending events
  * Claims stuck events using `XCLAIM`
  * Reprocesses them safely

This guarantees **at-least-once delivery**.

---

## ğŸš€ How to Run Locally

### 1ï¸âƒ£ Start Redis

```bash
redis-server
```

*or using Docker*

```bash
docker run -p 6379:6379 redis
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Start Server

```bash
node src/index.js
```

Server runs on:

```
http://localhost:3000
```

---

## ğŸ¯ Project Status

âœ… Core features completed

âœ… Stable & tested locally

âœ… Ready for GitHub

Possible future improvements (optional):

* Persistent database storage
* Multiple consumers
* Rate limiting
* Docker Compose

---

## ğŸ“Œ Why This Project Matters

This project demonstrates:

* Understanding of **distributed systems basics**
* Real-world **message queue patterns**
* Fault tolerance & recovery strategies

---

## Future Enhancements
* Technical
  * Persist processed events in PostgreSQL / MongoDB
  * Multiple consumers for parallel processing
  * Docker Compose setup (API + Redis)
  * Authentication & rate limiting

* System
  * Event schema versioning
  * Exponential backoff retry
  * Separate retry stream
  * Admin dashboard / alerts on DLQ growth

---

## ğŸ“ Notes

* Keep redis running (port 6379)
* Use unique CONSUMER_NAME if scaling consumers
* MAX_RETRIES can be configured in retry.js
* IDLE_TIME_MS in recovery.js controls when pending events are reclaimed

---